{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqgA_yPbGFnM"
      },
      "source": [
        "#TASK #1: UNDERSTAND THE PROBLEM STATEMENT & BUSINESS CASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttbJv3I1rpn3"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=139zlnLGzYen-GbcnkXQZs44tf7OqV8e4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n66xj4BGKWM"
      },
      "source": [
        "#TASK #2: IMPORT DATASETS AND LIBRARIES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sPZpiBGYcYB"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVxYSMIUxx_U"
      },
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from copy import copy\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbxX37RAYEXS"
      },
      "source": [
        "# Read stock prices data\n",
        "stock_price_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Python & ML in Finance/Part 3. AI and ML in Finance/stock.csv')\n",
        "stock_price_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbBDdWcm9dLH"
      },
      "source": [
        "# Read the stocks volume data\n",
        "stock_vol_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Python & ML in Finance/Part 3. AI and ML in Finance/stock_volume.csv\")\n",
        "stock_vol_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et-6_Df_Gcod"
      },
      "source": [
        "# Sort the data based on Date\n",
        "stock_price_df = stock_price_df.sort_values(by = ['Date'])\n",
        "stock_price_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROFg8mJP9s0W"
      },
      "source": [
        "# Sort the data based on Date\n",
        "stock_vol_df = stock_vol_df.sort_values(by = ['Date'])\n",
        "stock_vol_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvihVJ0UZ2fe"
      },
      "source": [
        "# Check if Null values exist in stock prices data\n",
        "stock_price_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkMQnKIZ099u"
      },
      "source": [
        "# Check if Null values exist in stocks volume data\n",
        "stock_vol_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4nClRot5F4y"
      },
      "source": [
        "# Get stock prices dataframe info\n",
        "stock_price_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onwN8ky494An"
      },
      "source": [
        "# Get stock volume dataframe info\n",
        "stock_vol_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mvKrUmhmxeR"
      },
      "source": [
        "stock_vol_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nFC4pHcGr57"
      },
      "source": [
        "#TASK #3: PERFORM EXPLORATORY DATA ANALYSIS AND VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDkIJX8rEMxC"
      },
      "source": [
        "# Function to normalize stock prices based on their initial price\n",
        "def normalize(df):\n",
        "  x = df.copy()\n",
        "  for i in x.columns[1:]:\n",
        "    x[i] = x[i]/x[i][0]\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGNiYwkkLqfu"
      },
      "source": [
        "# Function to plot interactive plots using Plotly Express\n",
        "def interactive_plot(df, title):\n",
        "  fig = px.line(title = title)\n",
        "  for i in df.columns[1:]:\n",
        "    fig.add_scatter(x = df['Date'], y = df[i], name = i)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzkZZQ5NO2AJ"
      },
      "source": [
        "# plot interactive chart for stocks data\n",
        "interactive_plot(stock_price_df, 'Stock Prices')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFE61_E-gu5V"
      },
      "source": [
        "# TASK #4: PREPARE THE DATA BEFORE TRAINING THE AI/ML MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWflwv1or9s_"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1uXYYHfgeJyncu4BZRAooTC4iCclH9e9B)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA1XN-zgBMHI"
      },
      "source": [
        "# Function to concatenate the date, stock price, and volume in one dataframe\n",
        "def individual_stock(price_df, vol_df, name):\n",
        "    return pd.DataFrame({'Date': price_df['Date'], 'Close': price_df[name], 'Volume': vol_df[name]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP_-Yyay__cb"
      },
      "source": [
        "# Function to return the input/output (target) data for AI/ML Model\n",
        "# Note that our goal is to predict the future stock price\n",
        "# Target stock price today will be tomorrow's price\n",
        "def trading_window(data):\n",
        "\n",
        "  # 1 day window\n",
        "  n = 1\n",
        "\n",
        "  # Create a column containing the prices for the next 1 days\n",
        "  data['Target'] = data[['Close']].shift(-n)\n",
        "\n",
        "  # return the new dataset\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VdtCh0BB_vH"
      },
      "source": [
        "# Let's test the functions and get individual stock prices and volumes for AAPL\n",
        "price_volume_df = individual_stock(stock_price_df, stock_vol_df, 'AAPL')\n",
        "price_volume_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZ9a0mMCYq-"
      },
      "source": [
        "price_volume_target_df = trading_window(price_volume_df)\n",
        "price_volume_target_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UdkMEUcD18c"
      },
      "source": [
        "# Remove the last row as it will be a null value\n",
        "price_volume_target_df = price_volume_target_df[:-1]\n",
        "price_volume_target_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M08n1GlnZtlL"
      },
      "source": [
        "# Scale the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "price_volume_target_scaled_df = sc.fit_transform(price_volume_target_df.drop(columns = ['Date']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zq-g6ifiAxz"
      },
      "source": [
        "price_volume_target_scaled_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO3fljBwZ7S9"
      },
      "source": [
        "price_volume_target_scaled_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvVJa_UvD_uB"
      },
      "source": [
        "# Creating Feature and Target\n",
        "X = price_volume_target_scaled_df[:,:2]\n",
        "y = price_volume_target_scaled_df[:,2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0azmQvOXEsGW"
      },
      "source": [
        "# Converting dataframe to arrays\n",
        "# X = np.asarray(X)\n",
        "# y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIlzHnyxGoXI"
      },
      "source": [
        "# Spliting the data this way, since order is important in time-series\n",
        "# Note that we did not use train test split with it's default settings since it shuffles the data\n",
        "split = int(0.65 * len(X))\n",
        "X_train = X[:split]\n",
        "y_train = y[:split]\n",
        "X_test = X[split:]\n",
        "y_test = y[split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cg-HNcvFJak"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH88gQ1vif5j"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFtSZ4_lk4Aq"
      },
      "source": [
        "# Define a data plotting function\n",
        "def show_plot(data, title):\n",
        "  plt.figure(figsize = (13, 5))\n",
        "  plt.plot(data, linewidth = 3)\n",
        "  plt.title(title)\n",
        "  plt.grid()\n",
        "\n",
        "show_plot(X_train, 'Training Data')\n",
        "show_plot(X_test, 'Testing Data')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FVSgRmFFkW5"
      },
      "source": [
        "# TASK #5: BUILD AND TRAIN A RIDGE LINEAR REGRESSION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QECbURfqFvBP"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "# Note that Ridge regression performs linear least squares with L2 regularization.\n",
        "# Create and train the Ridge Linear Regression  Model\n",
        "regression_model = Ridge()\n",
        "regression_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFxXpwVfWPaC"
      },
      "source": [
        "# Test the model and calculate its accuracy\n",
        "lr_accuracy = regression_model.score(X_test, y_test)\n",
        "print(\"Linear Regression Score: \", lr_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Jw5dmMJGwP"
      },
      "source": [
        "# Make Prediction\n",
        "predicted_prices = regression_model.predict(X)\n",
        "predicted_prices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VNXZpyehMct"
      },
      "source": [
        "# Append the predicted values into a list\n",
        "Predicted = []\n",
        "for i in predicted_prices:\n",
        "  Predicted.append(i[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYzR5OwB8a4E"
      },
      "source": [
        "len(Predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYGT3NAlah-1"
      },
      "source": [
        "# Append the close values to the list\n",
        "close = []\n",
        "for i in price_volume_target_scaled_df:\n",
        "  close.append(i[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAZJ5HnsJjDH"
      },
      "source": [
        "# Create a dataframe based on the dates in the individual stock data\n",
        "df_predicted = price_volume_target_df[['Date']]\n",
        "df_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap51j2zMbukl"
      },
      "source": [
        "# Add the close values to the dataframe\n",
        "df_predicted['Close'] = close\n",
        "df_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTvlo0ZpJ2Sn"
      },
      "source": [
        "# Add the predicted values to the dataframe\n",
        "df_predicted['Prediction'] = Predicted\n",
        "df_predicted"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}